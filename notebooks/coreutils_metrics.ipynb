{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup # resolve path to 'src'\n",
    "from typing import Optional\n",
    "from build_parse import *\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs = [ CoreutilsProgram(progname) for progname in COREUTILS_PROG_NAMES ]\n",
    "prognames = [ prog.get_name() for prog in progs ]\n",
    "\n",
    "# Define the build options to test for each program\n",
    "debug_opts = BuildOptions(debug=True, strip=False, optimization=0)\n",
    "standard_opts = BuildOptions(debug=False, strip=False, optimization=0)\n",
    "strip_opts = BuildOptions(debug=False, strip=True, optimization=0)\n",
    "\n",
    "opts_sets = (debug_opts, standard_opts, strip_opts)\n",
    "\n",
    "# Get the parser functions\n",
    "dwarf_parser = get_parser(\"dwarf\")\n",
    "ghidra_parser = get_parser(\"ghidra\")\n",
    "\n",
    "# ensure that each program is built according to all variations of build options\n",
    "for prog in progs:\n",
    "    for opts in (debug_opts, standard_opts, strip_opts):\n",
    "        assert(prog.valid_build(opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the filename format for saving parsed ProgramInfo pickle objects\n",
    "def mangle_proginfo_save_name(parsername: str, prog: Program, opts: BuildOptions) -> str:\n",
    "    return \"{}.{}.pickle\".format(prog.get_binary_name(opts), parsername)\n",
    "\n",
    "def get_proginfo_save_path(parsername: str, prog: Program, opts: BuildOptions) -> Path:\n",
    "    return PICKLE_CACHE_DIR.joinpath(mangle_proginfo_save_name(parsername, prog, opts))\n",
    "\n",
    "def save_proginfo(proginfo: ProgramInfo, parsername: str, prog: Program, opts: BuildOptions):\n",
    "    save_pickle(proginfo, get_proginfo_save_path(parsername, prog, opts))\n",
    "\n",
    "def load_proginfo(parsername: str, prog: Program, opts: BuildOptions) -> ProgramInfo:\n",
    "    return load_pickle(get_proginfo_save_path(parsername, prog, opts))\n",
    "\n",
    "# the filename format for saving UnoptimizedProgramInfoCompare2 objects\n",
    "def mangle_cmp_save_name(prog: Program, opts: BuildOptions) -> str:\n",
    "    return \"{}.cmp.pickle\".format(prog.get_binary_name(opts))\n",
    "\n",
    "def get_cmp_save_path(prog: Program, opts: BuildOptions) -> Path:\n",
    "    return PICKLE_CACHE_DIR.joinpath(mangle_cmp_save_name(prog, opts))\n",
    "\n",
    "def save_cmp(cmp: UnoptimizedProgramInfoCompare2, prog: Program, opts: BuildOptions):\n",
    "    save_pickle(cmp, get_cmp_save_path(prog, opts))\n",
    "\n",
    "def load_cmp(prog: Program, opts: BuildOptions) -> UnoptimizedProgramInfoCompare2:\n",
    "    return load_pickle(get_cmp_save_path(prog, opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DWARF: only parse with the debug build options\n",
    "# Ghidra: parse with all variations of build options\n",
    "# Cache the results in local pickle_cache directory, named based on the 'mangle' scheme\n",
    "\n",
    "reparse = False # should we re-parse even if we already parsed and cached a program?\n",
    "skip_parsing = True # should we skip the parsing? set to True if we already parsed & cached\n",
    "\n",
    "class ParseException(Exception):\n",
    "    pass\n",
    "\n",
    "def parse(parser: Callable, prog: Program, opts: BuildOptions) -> Optional[ProgramInfo]:\n",
    "    try:\n",
    "        return parser(prog.get_binary_path(opts))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "failed = []\n",
    "if not skip_parsing:\n",
    "    for prog in progs:\n",
    "        dwarf_debug_savepath = get_proginfo_save_path(\"dwarf\", prog, debug_opts)\n",
    "        if reparse or not dwarf_debug_savepath.exists():\n",
    "            dwarf_debug = parse(dwarf_parser, prog, debug_opts)\n",
    "            if dwarf_debug is None:\n",
    "                failed.append((\"dwarf\", prog.get_name(), debug_opts))\n",
    "            else:\n",
    "                save_pickle(dwarf_debug, dwarf_debug_savepath)\n",
    "\n",
    "        for opts in opts_sets:\n",
    "            ghidra_parse_savepath = get_proginfo_save_path(\"ghidra\", prog, opts)\n",
    "            ghidra_parse = parse(ghidra_parser, prog, opts)\n",
    "            if reparse or not dwarf_debug_savepath.exists():\n",
    "                if ghidra_parse is None:\n",
    "                    failed.append((\"ghidra\", prog.get_name(), opts))\n",
    "                else:\n",
    "                    save_pickle(ghidra_parse, ghidra_parse_savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each program & build options combination, compute & store comparison object\n",
    "\n",
    "recompare = False\n",
    "skip_comparisons = False\n",
    "\n",
    "failed = []\n",
    "if not skip_comparisons:\n",
    "    for prog in progs:\n",
    "        # load the DWARF ground-truth ProgramInfo\n",
    "        dwarf_proginfo = load_pickle(get_proginfo_save_path(\"dwarf\", prog, debug_opts))\n",
    "        assert(dwarf_proginfo is not None)\n",
    "\n",
    "        # for each set of compilation options, load the Ghidra decompiler ProgramInfo\n",
    "        # then compute & store the comparison object\n",
    "        for opts in opts_sets:\n",
    "            cmp_save_path = get_cmp_save_path(prog, opts)\n",
    "            if recompare or not cmp_save_path.exists():\n",
    "                ghidra_proginfo = load_pickle(get_proginfo_save_path(\"ghidra\", prog, opts))\n",
    "                assert(ghidra_proginfo is not None)\n",
    "                try:\n",
    "                    cmp = compare2(dwarf_proginfo, ghidra_proginfo)\n",
    "                    save_pickle(cmp, get_cmp_save_path(prog, opts))\n",
    "                except:\n",
    "                    failed.append((prog.get_name(), opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each opts, compute the tables\n",
    "\n",
    "def mangle_table_save_name(\n",
    "    tablename: str,\n",
    "    opts: BuildOptions\n",
    ") -> str:\n",
    "    return \"{}{}.csv\".format(tablename, suffix(opts))\n",
    "\n",
    "def mangle_table_display_name(\n",
    "    tablename: str,\n",
    "    opts: BuildOptions\n",
    ") -> str:\n",
    "    def _suffix(opts: BuildOptions) -> str:\n",
    "        return \"(optimization={}, stripped={}, debug={})\".format(opts.optimization, opts.strip, opts.debug)\n",
    "\n",
    "    return \"{} {}\".format(tablename, _suffix(opts))\n",
    "\n",
    "def get_table_save_path(\n",
    "    tablename: str,\n",
    "    opts: BuildOptions\n",
    ") -> Path:\n",
    "    return DATA_DIR.joinpath(mangle_table_save_name(tablename, opts))\n",
    "\n",
    "def load_table(\n",
    "    tablename: str,\n",
    "    opts: BuildOptions\n",
    ") -> pd.DataFrame:\n",
    "    return pd.read_csv(get_table_save_path(tablename, opts), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute = False\n",
    "skip_compute_metrics = True\n",
    "\n",
    "metrics_groups = make_metrics()\n",
    "\n",
    "dfs = []\n",
    "tablenames = []\n",
    "\n",
    "if not skip_compute_metrics:\n",
    "    for opts in opts_sets:\n",
    "        cmps = [ load_cmp(prog, opts) for prog in progs ]\n",
    "        for grp in metrics_groups:\n",
    "            save_path = get_table_save_path(grp.get_name(), opts)\n",
    "            tablename = mangle_table_display_name(grp.get_display_name(), opts)\n",
    "            print(tablename)\n",
    "            if recompute or not save_path.exists():\n",
    "                df = compute_comparisons_metrics_dataframe(prognames, cmps, grp.get_metrics())\n",
    "                tablenames.append(tablename)\n",
    "                dfs.append(df)\n",
    "                df.to_csv(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ground truth data bytes</th>\n",
       "      <th>Bytes found</th>\n",
       "      <th>Bytes missed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[</th>\n",
       "      <td>4463</td>\n",
       "      <td>4320</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2sum</th>\n",
       "      <td>4472</td>\n",
       "      <td>4304</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base32</th>\n",
       "      <td>2671</td>\n",
       "      <td>2548</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base64</th>\n",
       "      <td>2699</td>\n",
       "      <td>2608</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basename</th>\n",
       "      <td>2193</td>\n",
       "      <td>2102</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vdir</th>\n",
       "      <td>52786</td>\n",
       "      <td>44647</td>\n",
       "      <td>8139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wc</th>\n",
       "      <td>53798</td>\n",
       "      <td>3528</td>\n",
       "      <td>50270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who</th>\n",
       "      <td>5007</td>\n",
       "      <td>4904</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whoami</th>\n",
       "      <td>2069</td>\n",
       "      <td>1970</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>2166</td>\n",
       "      <td>2067</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Ground truth data bytes  Bytes found  Bytes missed\n",
       "[                            4463         4320           143\n",
       "b2sum                        4472         4304           168\n",
       "base32                       2671         2548           123\n",
       "base64                       2699         2608            91\n",
       "basename                     2193         2102            91\n",
       "...                           ...          ...           ...\n",
       "vdir                        52786        44647          8139\n",
       "wc                          53798         3528         50270\n",
       "who                          5007         4904           103\n",
       "whoami                       2069         1970            99\n",
       "yes                          2166         2067            99\n",
       "\n",
       "[105 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# for opts in opts_sets:\n",
    "#     for grp in metrics_groups:\n",
    "#         save_path = get_table_save_path(grp.get_name(), opts)\n",
    "#         tablename = mangle_table_display_name(grp.get_display_name(), opts)\n",
    "\n",
    "df = load_table(metrics_groups[0].get_name(), opts)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebf8bf05a68ebde7d71715735c34f46ac9aa39a0c4d11ea58f3fb78ab998520e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
