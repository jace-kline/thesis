{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup # resolve path to 'src'\n",
    "from typing import Optional\n",
    "from build_parse import *\n",
    "from metrics import *\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs = [ CoreutilsProgram(progname) for progname in COREUTILS_PROG_NAMES ]\n",
    "prognames = [ prog.get_name() for prog in progs ]\n",
    "\n",
    "prognames_analyze = [ \"stat\", \"nohup\", \"pinky\", \"csplit\", \"ginstall\", \"fmt\", \"df\", \"join\", \"expr\", \"seq\", \"unexpand\", \"tsort\", \"tee\", \"base64\", \"sum\", \"cksum\", \"wc\" ]\n",
    "progs_analyze = []\n",
    "for progname in prognames_analyze:\n",
    "    for prog in progs:\n",
    "        if progname == prog.get_name():\n",
    "            progs_analyze.append(prog)\n",
    "            break\n",
    "\n",
    "def prog_from_progname(progname: str) -> Program:\n",
    "    for prog in progs:\n",
    "        if progname == prog.get_name():\n",
    "            return prog\n",
    "\n",
    "# Define the build options to test for each program\n",
    "debug_opts = BuildOptions(debug=True, strip=False, optimization=0)\n",
    "standard_opts = BuildOptions(debug=False, strip=False, optimization=0)\n",
    "strip_opts = BuildOptions(debug=False, strip=True, optimization=0)\n",
    "\n",
    "opts_sets = (debug_opts, standard_opts, strip_opts)\n",
    "\n",
    "# Get the parser functions\n",
    "dwarf_parser = get_parser(\"dwarf\")\n",
    "ghidra_parser = get_parser(\"ghidra\")\n",
    "\n",
    "# ensure that each program is built according to all variations of build options\n",
    "for prog in progs:\n",
    "    for opts in (debug_opts, standard_opts, strip_opts):\n",
    "        assert(prog.valid_build(opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the filename format for saving parsed ProgramInfo pickle objects\n",
    "def mangle_proginfo_save_name(parsername: str, prog: Program, opts: BuildOptions) -> str:\n",
    "    return \"{}.{}.pickle\".format(prog.get_binary_name(opts), parsername)\n",
    "\n",
    "def get_proginfo_save_path(parsername: str, prog: Program, opts: BuildOptions) -> Path:\n",
    "    return PICKLE_CACHE_DIR.joinpath(mangle_proginfo_save_name(parsername, prog, opts))\n",
    "\n",
    "def save_proginfo(proginfo: ProgramInfo, parsername: str, prog: Program, opts: BuildOptions):\n",
    "    save_pickle(proginfo, get_proginfo_save_path(parsername, prog, opts))\n",
    "\n",
    "def load_proginfo(parsername: str, prog: Program, opts: BuildOptions) -> ProgramInfo:\n",
    "    return load_pickle(get_proginfo_save_path(parsername, prog, opts))\n",
    "\n",
    "# the filename format for saving UnoptimizedProgramInfoCompare2 objects\n",
    "def mangle_cmp_save_name(prog: Program, opts: BuildOptions) -> str:\n",
    "    return \"{}.cmp.pickle\".format(prog.get_binary_name(opts))\n",
    "\n",
    "def get_cmp_save_path(prog: Program, opts: BuildOptions) -> Path:\n",
    "    return PICKLE_CACHE_DIR.joinpath(mangle_cmp_save_name(prog, opts))\n",
    "\n",
    "def save_cmp(cmp: UnoptimizedProgramInfoCompare2, prog: Program, opts: BuildOptions):\n",
    "    save_pickle(cmp, get_cmp_save_path(prog, opts))\n",
    "\n",
    "def load_cmp(prog: Program, opts: BuildOptions) -> UnoptimizedProgramInfoCompare2:\n",
    "    return load_pickle(get_cmp_save_path(prog, opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DWARF: only parse with the debug build options\n",
    "# Ghidra: parse with all variations of build options\n",
    "# Cache the results in local pickle_cache directory, named based on the 'mangle' scheme\n",
    "\n",
    "reparse = False # should we re-parse even if we already parsed and cached a program?\n",
    "skip_parsing = True # should we skip the parsing? set to True if we already parsed & cached\n",
    "\n",
    "class ParseException(Exception):\n",
    "    pass\n",
    "\n",
    "def parse(parser: Callable, prog: Program, opts: BuildOptions) -> Optional[ProgramInfo]:\n",
    "    try:\n",
    "        return parser(prog.get_binary_path(opts))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "failed = []\n",
    "if not skip_parsing:\n",
    "    for prog in progs:\n",
    "        dwarf_debug_savepath = get_proginfo_save_path(\"dwarf\", prog, debug_opts)\n",
    "        if reparse or not dwarf_debug_savepath.exists():\n",
    "            dwarf_debug = parse(dwarf_parser, prog, debug_opts)\n",
    "            if dwarf_debug is None:\n",
    "                failed.append((\"dwarf\", prog.get_name(), debug_opts))\n",
    "            else:\n",
    "                save_pickle(dwarf_debug, dwarf_debug_savepath)\n",
    "\n",
    "        for opts in opts_sets:\n",
    "            ghidra_parse_savepath = get_proginfo_save_path(\"ghidra\", prog, opts)\n",
    "            ghidra_parse = parse(ghidra_parser, prog, opts)\n",
    "            if reparse or not dwarf_debug_savepath.exists():\n",
    "                if ghidra_parse is None:\n",
    "                    failed.append((\"ghidra\", prog.get_name(), opts))\n",
    "                else:\n",
    "                    save_pickle(ghidra_parse, ghidra_parse_savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each program & build options combination, compute & store comparison object\n",
    "\n",
    "recompare = False\n",
    "skip_comparisons = True\n",
    "\n",
    "failed = []\n",
    "if not skip_comparisons:\n",
    "    for prog in progs:\n",
    "        # load the DWARF ground-truth ProgramInfo\n",
    "        dwarf_proginfo = load_pickle(get_proginfo_save_path(\"dwarf\", prog, debug_opts))\n",
    "        assert(dwarf_proginfo is not None)\n",
    "\n",
    "        # for each set of compilation options, load the Ghidra decompiler ProgramInfo\n",
    "        # then compute & store the comparison object\n",
    "        for opts in opts_sets:\n",
    "            cmp_save_path = get_cmp_save_path(prog, opts)\n",
    "            if recompare or not cmp_save_path.exists():\n",
    "                ghidra_proginfo = load_pickle(get_proginfo_save_path(\"ghidra\", prog, opts))\n",
    "                assert(ghidra_proginfo is not None)\n",
    "                try:\n",
    "                    cmp = compare2(dwarf_proginfo, ghidra_proginfo)\n",
    "                    save_pickle(cmp, get_cmp_save_path(prog, opts))\n",
    "                except:\n",
    "                    failed.append((prog.get_name(), opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each opts, compute the tables\n",
    "\n",
    "def mangle_table_save_name(\n",
    "    tablename: str,\n",
    "    opts: BuildOptions\n",
    ") -> str:\n",
    "    return \"{}{}.csv\".format(tablename, suffix(opts))\n",
    "\n",
    "def mangle_table_display_name(\n",
    "    tablename: str,\n",
    "    opts: BuildOptions\n",
    ") -> str:\n",
    "    def _suffix(opts: BuildOptions) -> str:\n",
    "        return \"(optimization={}, stripped={}, debug={})\".format(opts.optimization, opts.strip, opts.debug)\n",
    "\n",
    "    return \"{} {}\".format(tablename, _suffix(opts))\n",
    "\n",
    "def get_table_save_path(\n",
    "    tablename: str,\n",
    "    opts: BuildOptions\n",
    ") -> Path:\n",
    "    return DATA_DIR.joinpath(mangle_table_save_name(tablename, opts))\n",
    "\n",
    "def load_table(\n",
    "    tablename: str,\n",
    "    opts: BuildOptions\n",
    ") -> pd.DataFrame:\n",
    "    return pd.read_csv(get_table_save_path(tablename, opts), index_col=0)\n",
    "\n",
    "def load_table_filter_analyzed(tablename: str, opts: BuildOptions) -> pd.DataFrame:\n",
    "    return load_table(tablename, opts).filter(prognames_analyze, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute = False\n",
    "skip_compute_metrics = True\n",
    "\n",
    "metrics_groups = make_metrics()\n",
    "\n",
    "if not skip_compute_metrics:\n",
    "    for opts in opts_sets:\n",
    "        cmps = [ load_cmp(prog, opts) for prog in progs ]\n",
    "        for grp in metrics_groups:\n",
    "            save_path = get_table_save_path(grp.get_name(), opts)\n",
    "            tablename = mangle_table_display_name(grp.get_display_name(), opts)\n",
    "            print(tablename)\n",
    "            if recompute or not save_path.exists():\n",
    "                df = compute_comparisons_metrics_dataframe(prognames, cmps, grp.get_metrics())\n",
    "                df.to_csv(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes_group = metrics_groups[0]\n",
    "functions_group = metrics_groups[1]\n",
    "varnodes_group = metrics_groups[2]\n",
    "decomposed_varnodes_group = metrics_groups[9]\n",
    "array_comparisons_group = metrics_groups[13]\n",
    "\n",
    "primitive_metatypes = [MetaType.INT, MetaType.FLOAT, MetaType.POINTER]\n",
    "complex_metatypes = [MetaType.ARRAY, MetaType.STRUCT, MetaType.UNION]\n",
    "\n",
    "def varnodes_group_metatype(metatype: int) -> MetricsGroup:\n",
    "    _map = dict([ (meta, i) for i, meta in enumerate(primitive_metatypes + complex_metatypes, 3) ])\n",
    "    return _map[metatype]\n",
    "\n",
    "def decomposed_varnodes_group_metatype(metatype: int) -> MetricsGroup:\n",
    "    _map = dict([ (meta, i) for i, meta in enumerate(primitive_metatypes, 10) ])\n",
    "    return _map[metatype]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for opts in opts_sets:\n",
    "#     for grp in metrics_groups:\n",
    "#         save_path = get_table_save_path(grp.get_name(), opts)\n",
    "#         tablename = mangle_table_display_name(grp.get_display_name(), opts)\n",
    "\n",
    "# df = load_table_filter_analyzed(metrics_groups[0].get_name(), opts)\n",
    "# df\n",
    "\n",
    "# cmp = load_cmp(prog_from_progname(\"wc\"), opts)\n",
    "\n",
    "# varnodes_missed(cmp)\n",
    "def display_analyzed_tables(opts_sets: BuildOptions, metrics_groups: List[MetricsGroup]):\n",
    "    for opts in opts_sets:\n",
    "        for grp in metrics_groups:\n",
    "            table_display_name = mangle_table_display_name(grp.get_display_name(), opts)\n",
    "            df = load_table_filter_analyzed(grp.get_name(), opts)\n",
    "\n",
    "            print(\"{} {} {}\".format(\"-\"*10, table_display_name, \"-\"*10))\n",
    "            display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- DATA BYTES (optimization=0, stripped=False, debug=False) ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ground truth data bytes</th>\n",
       "      <th>Bytes found</th>\n",
       "      <th>Bytes missed</th>\n",
       "      <th>Bytes recovery fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>stat</th>\n",
       "      <td>9167</td>\n",
       "      <td>8617</td>\n",
       "      <td>550</td>\n",
       "      <td>0.940002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nohup</th>\n",
       "      <td>2299</td>\n",
       "      <td>2196</td>\n",
       "      <td>103</td>\n",
       "      <td>0.955198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pinky</th>\n",
       "      <td>5002</td>\n",
       "      <td>4911</td>\n",
       "      <td>91</td>\n",
       "      <td>0.981807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>csplit</th>\n",
       "      <td>31426</td>\n",
       "      <td>30330</td>\n",
       "      <td>1096</td>\n",
       "      <td>0.965124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fmt</th>\n",
       "      <td>47599</td>\n",
       "      <td>47508</td>\n",
       "      <td>91</td>\n",
       "      <td>0.998088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df</th>\n",
       "      <td>13992</td>\n",
       "      <td>11788</td>\n",
       "      <td>2204</td>\n",
       "      <td>0.842481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>join</th>\n",
       "      <td>3126</td>\n",
       "      <td>3023</td>\n",
       "      <td>103</td>\n",
       "      <td>0.967051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expr</th>\n",
       "      <td>30758</td>\n",
       "      <td>29415</td>\n",
       "      <td>1343</td>\n",
       "      <td>0.956337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seq</th>\n",
       "      <td>4357</td>\n",
       "      <td>4208</td>\n",
       "      <td>149</td>\n",
       "      <td>0.965802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unexpand</th>\n",
       "      <td>2344</td>\n",
       "      <td>2253</td>\n",
       "      <td>91</td>\n",
       "      <td>0.961177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tsort</th>\n",
       "      <td>2391</td>\n",
       "      <td>2284</td>\n",
       "      <td>107</td>\n",
       "      <td>0.955249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tee</th>\n",
       "      <td>10555</td>\n",
       "      <td>10460</td>\n",
       "      <td>95</td>\n",
       "      <td>0.991000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base64</th>\n",
       "      <td>2699</td>\n",
       "      <td>2608</td>\n",
       "      <td>91</td>\n",
       "      <td>0.966284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>4413</td>\n",
       "      <td>4290</td>\n",
       "      <td>123</td>\n",
       "      <td>0.972128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cksum</th>\n",
       "      <td>162392</td>\n",
       "      <td>29876</td>\n",
       "      <td>132516</td>\n",
       "      <td>0.183975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wc</th>\n",
       "      <td>36613</td>\n",
       "      <td>3528</td>\n",
       "      <td>33085</td>\n",
       "      <td>0.096359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Ground truth data bytes  Bytes found  Bytes missed  \\\n",
       "stat                         9167         8617           550   \n",
       "nohup                        2299         2196           103   \n",
       "pinky                        5002         4911            91   \n",
       "csplit                      31426        30330          1096   \n",
       "fmt                         47599        47508            91   \n",
       "df                          13992        11788          2204   \n",
       "join                         3126         3023           103   \n",
       "expr                        30758        29415          1343   \n",
       "seq                          4357         4208           149   \n",
       "unexpand                     2344         2253            91   \n",
       "tsort                        2391         2284           107   \n",
       "tee                         10555        10460            95   \n",
       "base64                       2699         2608            91   \n",
       "sum                          4413         4290           123   \n",
       "cksum                      162392        29876        132516   \n",
       "wc                          36613         3528         33085   \n",
       "\n",
       "          Bytes recovery fraction  \n",
       "stat                     0.940002  \n",
       "nohup                    0.955198  \n",
       "pinky                    0.981807  \n",
       "csplit                   0.965124  \n",
       "fmt                      0.998088  \n",
       "df                       0.842481  \n",
       "join                     0.967051  \n",
       "expr                     0.956337  \n",
       "seq                      0.965802  \n",
       "unexpand                 0.961177  \n",
       "tsort                    0.955249  \n",
       "tee                      0.991000  \n",
       "base64                   0.966284  \n",
       "sum                      0.972128  \n",
       "cksum                    0.183975  \n",
       "wc                       0.096359  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_analyzed_tables((standard_opts,), (bytes_group,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<VarnodeCompareRecord varnode=<Varnode address=<STACK:-0x30> datatype=<ARRAY subtype=char dimensions=(21,) size=21>> level=1>,\n",
       " <VarnodeCompareRecord varnode=<Varnode address=<STACK:-0x60> datatype=<STRUCT quoting_options membertypes=5 size=56>> level=1>,\n",
       " <VarnodeCompareRecord varnode=<Varnode address=<STACK:-0x50> datatype=<STRUCT quoting_options membertypes=5 size=56>> level=1>,\n",
       " <VarnodeCompareRecord varnode=<Varnode address=<STACK:-0x50> datatype=<STRUCT quoting_options membertypes=5 size=56>> level=1>,\n",
       " <VarnodeCompareRecord varnode=<Varnode address=<STACK:-0x50> datatype=<STRUCT quoting_options membertypes=5 size=56>> level=1>,\n",
       " <VarnodeCompareRecord varnode=<Varnode address=<STACK:-0x70> datatype=<ARRAY subtype=char * dimensions=(10,) size=80>> level=1>,\n",
       " <VarnodeCompareRecord varnode=<Varnode address=<STACK:-0x120> datatype=<ARRAY subtype=char dimensions=(257,) size=257>> level=1>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp = load_cmp(prog_from_progname(\"wc\"), opts)\n",
    "truth = sum([ varnode.get_size() for varnode in varnodes_truth(cmp) ])\n",
    "missed = sum([ varnode.get_size() for varnode in varnodes_missed(cmp) ])\n",
    "overlapped = varnode_compare_records_matched_at_level(cmp, VarnodeCompareLevel.OVERLAP)\n",
    "overlapped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebf8bf05a68ebde7d71715735c34f46ac9aa39a0c4d11ea58f3fb78ab998520e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
