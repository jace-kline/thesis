{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup # resolve path to 'src'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Optional\n",
    "from build_parse import *\n",
    "from metrics import *\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs = [ CoreutilsProgram(progname) for progname in COREUTILS_PROG_NAMES ]\n",
    "prognames = [ prog.get_name() for prog in progs ]\n",
    "\n",
    "# Define the build options to test for each program\n",
    "debug_opts = BuildOptions(debug=True, strip=False, optimization=0)\n",
    "standard_opts = BuildOptions(debug=False, strip=False, optimization=0)\n",
    "strip_opts = BuildOptions(debug=False, strip=True, optimization=0)\n",
    "\n",
    "opts_sets = (strip_opts, standard_opts, debug_opts)\n",
    "opts_sets_keys = (\"strip\", \"standard\", \"debug\")\n",
    "\n",
    "# Get the parser functions\n",
    "dwarf_parser = get_parser(\"dwarf\")\n",
    "ghidra_parser = get_parser(\"ghidra\")\n",
    "\n",
    "varnode_compare_levels = list(VarnodeCompareLevel.range())\n",
    "varnode_compare_level_labels = [ \"Varnodes matched @ level {}\".format(VarnodeCompareLevel.to_string(level)) for level in VarnodeCompareLevel.range() ]\n",
    "\n",
    "primitive_metatypes = [MetaType.INT, MetaType.FLOAT, MetaType.POINTER]\n",
    "complex_metatypes = [MetaType.ARRAY, MetaType.STRUCT, MetaType.UNION]\n",
    "metatypes = primitive_metatypes + complex_metatypes\n",
    "metatype_labels = [ MetaType.repr(metatype) for metatype in metatypes ]\n",
    "\n",
    "# ensure that each program is built according to all variations of build options\n",
    "for prog in progs:\n",
    "    for opts in (debug_opts, standard_opts, strip_opts):\n",
    "        assert(prog.valid_build(opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the filename format for saving parsed ProgramInfo pickle objects\n",
    "def mangle_proginfo_save_name(parsername: str, prog: Program, opts: BuildOptions) -> str:\n",
    "    return \"{}.{}.pickle\".format(prog.get_binary_name(opts), parsername)\n",
    "\n",
    "def get_proginfo_save_path(parsername: str, prog: Program, opts: BuildOptions) -> Path:\n",
    "    return PICKLE_CACHE_DIR.joinpath(mangle_proginfo_save_name(parsername, prog, opts))\n",
    "\n",
    "def save_proginfo(proginfo: ProgramInfo, parsername: str, prog: Program, opts: BuildOptions):\n",
    "    save_pickle(proginfo, get_proginfo_save_path(parsername, prog, opts))\n",
    "\n",
    "def load_proginfo(parsername: str, prog: Program, opts: BuildOptions) -> ProgramInfo:\n",
    "    return load_pickle(get_proginfo_save_path(parsername, prog, opts))\n",
    "\n",
    "# the filename format for saving UnoptimizedProgramInfoCompare2 objects\n",
    "def mangle_cmp_save_name(prog: Program, opts: BuildOptions) -> str:\n",
    "    return \"{}.cmp.pickle\".format(prog.get_binary_name(opts))\n",
    "\n",
    "def get_cmp_save_path(prog: Program, opts: BuildOptions) -> Path:\n",
    "    return PICKLE_CACHE_DIR.joinpath(mangle_cmp_save_name(prog, opts))\n",
    "\n",
    "def save_cmp(cmp: UnoptimizedProgramInfoCompare2, prog: Program, opts: BuildOptions):\n",
    "    save_pickle(cmp, get_cmp_save_path(prog, opts))\n",
    "\n",
    "def load_cmp(prog: Program, opts: BuildOptions) -> UnoptimizedProgramInfoCompare2:\n",
    "    return load_pickle(get_cmp_save_path(prog, opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DWARF: only parse with the debug build options\n",
    "# Ghidra: parse with all variations of build options\n",
    "# Cache the results in local pickle_cache directory, named based on the 'mangle' scheme\n",
    "\n",
    "reparse = False # should we re-parse even if we already parsed and cached a program?\n",
    "skip_parsing = True # should we skip the parsing? set to True if we already parsed & cached\n",
    "\n",
    "class ParseException(Exception):\n",
    "    pass\n",
    "\n",
    "def parse(parser: Callable, prog: Program, opts: BuildOptions) -> Optional[ProgramInfo]:\n",
    "    try:\n",
    "        return parser(prog.get_binary_path(opts))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "failed = []\n",
    "if not skip_parsing:\n",
    "    for prog in progs:\n",
    "        dwarf_debug_savepath = get_proginfo_save_path(\"dwarf\", prog, debug_opts)\n",
    "        if reparse or not dwarf_debug_savepath.exists():\n",
    "            dwarf_debug = parse(dwarf_parser, prog, debug_opts)\n",
    "            if dwarf_debug is None:\n",
    "                failed.append((\"dwarf\", prog.get_name(), debug_opts))\n",
    "            else:\n",
    "                save_pickle(dwarf_debug, dwarf_debug_savepath)\n",
    "\n",
    "        for opts in opts_sets:\n",
    "            ghidra_parse_savepath = get_proginfo_save_path(\"ghidra\", prog, opts)\n",
    "            if reparse or not dwarf_debug_savepath.exists():\n",
    "                ghidra_parse = parse(ghidra_parser, prog, opts)\n",
    "                if ghidra_parse is None:\n",
    "                    failed.append((\"ghidra\", prog.get_name(), opts))\n",
    "                else:\n",
    "                    save_pickle(ghidra_parse, ghidra_parse_savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(failed)\n",
    "\n",
    "for prog in progs:\n",
    "    for opts in opts_sets:\n",
    "        assert(get_proginfo_save_path(\"ghidra\", prog, opts).exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each program & build options combination, compute & store comparison object\n",
    "\n",
    "recompare = False\n",
    "skip_comparisons = True\n",
    "\n",
    "failed = []\n",
    "if not skip_comparisons:\n",
    "    for prog in progs:\n",
    "        # load the DWARF ground-truth ProgramInfo\n",
    "        dwarf_proginfo = load_pickle(get_proginfo_save_path(\"dwarf\", prog, debug_opts))\n",
    "        assert(dwarf_proginfo is not None)\n",
    "\n",
    "        # for each set of compilation options, load the Ghidra decompiler ProgramInfo\n",
    "        # then compute & store the comparison object\n",
    "        for opts in opts_sets:\n",
    "            cmp_save_path = get_cmp_save_path(prog, opts)\n",
    "            if recompare or not cmp_save_path.exists():\n",
    "                ghidra_proginfo = load_pickle(get_proginfo_save_path(\"ghidra\", prog, opts))\n",
    "                assert(ghidra_proginfo is not None)\n",
    "                try:\n",
    "                    cmp = compare2(dwarf_proginfo, ghidra_proginfo)\n",
    "                    save_pickle(cmp, get_cmp_save_path(prog, opts))\n",
    "                except:\n",
    "                    failed.append((prog.get_name(), opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(failed)\n",
    "\n",
    "for prog in progs:\n",
    "    for opts in opts_sets:\n",
    "        assert(get_cmp_save_path(prog, opts).exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each opts, compute the tables\n",
    "\n",
    "TABLES_DIR = DATA_DIR.joinpath(\"tables\")\n",
    "\n",
    "def underscores_to_dashes(s: str) -> str:\n",
    "    return s.replace(\"_\", \"-\")\n",
    "\n",
    "def make_latex_label(tablename: str) -> str:\n",
    "    return \"table:\" + underscores_to_dashes(tablename)\n",
    "\n",
    "def mangle_table_save_name(\n",
    "    tablename: str,\n",
    "    opts: BuildOptions\n",
    ") -> str:\n",
    "    return underscores_to_dashes(\"{}{}.csv\".format(tablename, suffix(opts)))\n",
    "\n",
    "def mangle_latex_save_name(\n",
    "    tablename: str,\n",
    "    opts: BuildOptions\n",
    ") -> str:\n",
    "    return underscores_to_dashes(\"{}{}.tex\".format(tablename, suffix(opts)))\n",
    "\n",
    "def build_options_display_suffix(opts: BuildOptions) -> str:\n",
    "    return \"(optimization={}, stripped={}, debug={})\".format(opts.optimization, opts.strip, opts.debug)\n",
    "\n",
    "def mangle_table_display_name(\n",
    "    tablename: str,\n",
    "    opts: BuildOptions\n",
    ") -> str:\n",
    "\n",
    "    return \"{} {}\".format(tablename, build_options_display_suffix(opts))\n",
    "\n",
    "def get_table_save_path(\n",
    "    tablename: str,\n",
    "    opts: BuildOptions\n",
    ") -> Path:\n",
    "    return DATA_DIR.joinpath(mangle_table_save_name(tablename, opts))\n",
    "\n",
    "def get_latex_path(\n",
    "    tablename: str,\n",
    "    opts: BuildOptions\n",
    ") -> Path:\n",
    "    return TABLES_DIR.joinpath(mangle_latex_save_name(tablename, opts))\n",
    "\n",
    "def get_table_save_path_generic(\n",
    "    tablename: str\n",
    ") -> Path:\n",
    "    return DATA_DIR.joinpath(tablename + \".csv\")\n",
    "\n",
    "def get_latex_path_generic(\n",
    "    tablename: str\n",
    ") -> Path:\n",
    "    return TABLES_DIR.joinpath(\"{}.tex\".format(tablename))\n",
    "\n",
    "def load_table(\n",
    "    tablename: str,\n",
    "    multiindex: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    index_col = 0 if not multiindex else (0,1)\n",
    "    return pd.read_csv(DATA_DIR.joinpath(tablename + \".csv\"), index_col=index_col)\n",
    "\n",
    "def load_table_opts(\n",
    "    tablename: str,\n",
    "    opts: BuildOptions\n",
    ") -> pd.DataFrame:\n",
    "    return pd.read_csv(get_table_save_path(tablename, opts), index_col=0)\n",
    "\n",
    "def get_table_from_group(\n",
    "    grp: MetricsGroup,\n",
    "    opts: BuildOptions\n",
    ")-> pd.DataFrame:\n",
    "    return load_table_opts(grp.get_name(), opts)\n",
    "\n",
    "def opts_to_caption_suffix(opts: BuildOptions) -> str:\n",
    "    if opts.debug:\n",
    "        return \"(compilation = debug)\"\n",
    "    elif opts.strip:\n",
    "        return \"(compilation = stripped)\"\n",
    "    else:\n",
    "        return \"(compilation = standard)\"\n",
    "\n",
    "def latex_column_format_str(ncols: int, table_width_cm: float = 12) -> str:\n",
    "    col_width = table_width_cm / ncols\n",
    "    repeat_str = \"p{{{:.1f}cm}}\".format(col_width)\n",
    "    return \"l\" + repeat_str*ncols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_groups = make_metrics()\n",
    "\n",
    "bytes_group = metrics_groups[0]\n",
    "functions_group = metrics_groups[1]\n",
    "varnodes_group = metrics_groups[2]\n",
    "decomposed_varnodes_group = metrics_groups[9]\n",
    "array_comparisons_group = metrics_groups[13]\n",
    "\n",
    "def varnodes_group_metatype(metatype: int) -> MetricsGroup:\n",
    "    _map = dict([ (meta, i) for i, meta in enumerate(primitive_metatypes + complex_metatypes, 3) ])\n",
    "    return metrics_groups[_map[metatype]]\n",
    "\n",
    "varnodes_groups_metatypes = [ varnodes_group_metatype(metatype) for metatype in (primitive_metatypes + complex_metatypes) ]\n",
    "\n",
    "def decomposed_varnodes_group_metatype(metatype: int) -> MetricsGroup:\n",
    "    _map = dict([ (meta, i) for i, meta in enumerate(primitive_metatypes, 10) ])\n",
    "    return metrics_groups[_map[metatype]]\n",
    "\n",
    "decomposed_varnodes_groups_metatypes = [ decomposed_varnodes_group_metatype(metatype) for metatype in primitive_metatypes ]\n",
    "\n",
    "high_varnodes_groups = [varnodes_group] + varnodes_groups_metatypes\n",
    "decomposed_varnodes_groups = [decomposed_varnodes_group] + decomposed_varnodes_groups_metatypes\n",
    "\n",
    "def get_group_column_names(grp: MetricsGroup) -> List[str]:\n",
    "    return [ metric.get_display_name() for metric in grp.get_metrics() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute = False\n",
    "skip_compute_metrics = True\n",
    "\n",
    "if not skip_compute_metrics:\n",
    "    for opts in opts_sets:\n",
    "        cmps = [ load_cmp(prog, opts) for prog in progs ]\n",
    "        for grp in metrics_groups:\n",
    "            savepath = get_table_save_path(grp.get_name(), opts)\n",
    "            tablename = mangle_table_display_name(grp.get_display_name(), opts)\n",
    "            print(tablename)\n",
    "            if recompute or not savepath.exists():\n",
    "                df = compute_comparisons_metrics_dataframe(prognames, cmps, grp.get_metrics())\n",
    "                df.to_csv(savepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n",
      "/tmp/ipykernel_5195/1506676523.py:12: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(new_colnames, axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "skip_fix_colnames = False\n",
    "\n",
    "if not skip_fix_colnames:\n",
    "    for grp in metrics_groups:\n",
    "        for opts in opts_sets:\n",
    "            df = get_table_from_group(grp, opts)\n",
    "            ncols = df.shape[1]\n",
    "            new_colnames = get_group_column_names(grp)\n",
    "            new_ncols = len(new_colnames)\n",
    "            if new_ncols < ncols:\n",
    "                df = df.iloc[:,0:new_ncols]\n",
    "            df.set_axis(new_colnames, axis=1, inplace=True)\n",
    "            savepath = get_table_save_path(grp.get_name(), opts)\n",
    "            df.to_csv(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_fix_varnode_metrics = False\n",
    "\n",
    "# Add \"Varnodes fraction partially recovered\" & \"Varnodes fraction exactly recovered\" columns\n",
    "# to the varnodes tables (if not already done)\n",
    "if not skip_fix_varnode_metrics:\n",
    "    for grp in high_varnodes_groups + decomposed_varnodes_groups:\n",
    "        for opts in opts_sets:\n",
    "            df = get_table_from_group(grp, opts)\n",
    "            df[\"Varnodes fraction partially recovered\"] = df.iloc[:,2:6].sum(axis=1) / df.iloc[:,0]\n",
    "            df[\"Varnodes fraction exactly recovered\"] = df.iloc[:,5] / df.iloc[:,0]\n",
    "            savepath = get_table_save_path(grp.get_name(), opts)\n",
    "            df.to_csv(savepath)\n",
    "\n",
    "def get_varnode_group_average_stats(grp: MetricsGroup) -> pd.Series:\n",
    "    df = get_table_from_group(grp, opts)\n",
    "    return df.iloc[:,6:].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_generate_metatype_level_summaries = False\n",
    "\n",
    "if not skip_generate_metatype_level_summaries:\n",
    "    for opts in opts_sets:\n",
    "        raw_seriess = []\n",
    "        ratios_seriess = []\n",
    "        for metatype in metatypes:\n",
    "            metatype_str = MetaType.repr(metatype)\n",
    "            grp = varnodes_group_metatype(metatype)\n",
    "            df = get_table_from_group(grp, opts)\n",
    "            metatype_varnodes = df.iloc[:,0].sum()\n",
    "            varnodes_by_levels = df.iloc[:,1:6].sum(axis=0)\n",
    "            varnodes_by_levels.index = varnode_compare_level_labels\n",
    "            level_ratios = varnodes_by_levels / metatype_varnodes\n",
    "            raw_seriess.append(varnodes_by_levels)\n",
    "            ratios_seriess.append(level_ratios)\n",
    "\n",
    "        high_raw_df = pd.DataFrame(\n",
    "            raw_seriess,\n",
    "            index=[ MetaType.repr(metatype) for metatype in metatypes ],\n",
    "            columns=varnode_compare_level_labels\n",
    "        )\n",
    "        high_raw_tablename = \"metatype-match-levels\"\n",
    "        high_raw_savepath = get_table_save_path(high_raw_tablename, opts)\n",
    "        high_raw_df.to_csv(high_raw_savepath)\n",
    "        \n",
    "        high_ratios_df = pd.DataFrame(\n",
    "            ratios_seriess,\n",
    "            index=[ MetaType.repr(metatype) for metatype in metatypes ],\n",
    "            columns=varnode_compare_level_labels\n",
    "        )\n",
    "        high_ratios_tablename = \"metatype-match-levels-ratios\"\n",
    "        high_ratios_savepath = get_table_save_path(high_ratios_tablename, opts)\n",
    "        high_ratios_df.to_csv(high_ratios_savepath)\n",
    "\n",
    "        decomposed_raw_seriess = []\n",
    "        decomposed_ratios_seriess = []\n",
    "        for metatype in primitive_metatypes:\n",
    "            metatype_str = MetaType.repr(metatype)\n",
    "            grp = decomposed_varnodes_group_metatype(metatype)\n",
    "            df = get_table_from_group(grp, opts)\n",
    "            metatype_varnodes = df.iloc[:,0].sum()\n",
    "            varnodes_by_levels = df.iloc[:,1:6].sum(axis=0)\n",
    "            varnodes_by_levels.index = varnode_compare_level_labels\n",
    "            level_ratios = varnodes_by_levels / metatype_varnodes\n",
    "            decomposed_raw_seriess.append(varnodes_by_levels)\n",
    "            decomposed_ratios_seriess.append(level_ratios)\n",
    "\n",
    "        decomposed_raw_df = pd.DataFrame(\n",
    "            decomposed_raw_seriess,\n",
    "            index=[ MetaType.repr(metatype) for metatype in primitive_metatypes ],\n",
    "            columns=varnode_compare_level_labels\n",
    "        )\n",
    "        decomposed_raw_tablename = \"metatype-match-levels-decomposed\"\n",
    "        decomposed_raw_savepath = get_table_save_path(decomposed_raw_tablename, opts)\n",
    "        decomposed_raw_df.to_csv(decomposed_raw_savepath)\n",
    "\n",
    "        decomposed_ratios_df = pd.DataFrame(\n",
    "            decomposed_ratios_seriess,\n",
    "            index=[ MetaType.repr(metatype) for metatype in primitive_metatypes ],\n",
    "            columns=varnode_compare_level_labels\n",
    "        )\n",
    "        decomposed_ratios_tablename = \"metatype-match-levels-ratios-decomposed\"\n",
    "        decomposed_ratios_savepath = get_table_save_path(decomposed_ratios_tablename, opts)\n",
    "        decomposed_ratios_df.to_csv(decomposed_ratios_savepath)\n",
    "\n",
    "def get_metatype_match_levels_table(\n",
    "    opts: BuildOptions,\n",
    "    primitive: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    tablename = \"metatype-match-levels\"\n",
    "    if primitive:\n",
    "        tablename += \"-decomposed\"\n",
    "    return load_table_opts(tablename, opts)\n",
    "\n",
    "def get_metatype_match_levels_ratios_table(\n",
    "    opts: BuildOptions,\n",
    "    primitive: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    tablename = \"metatype-match-levels-ratios\"\n",
    "    if primitive:\n",
    "        tablename += \"-decomposed\"\n",
    "    return load_table_opts(tablename, opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_generate_metatype_recovery_summaries = False\n",
    "\n",
    "tablename = \"metatype-recovery-summary\"\n",
    "\n",
    "if not skip_generate_metatype_recovery_summaries:\n",
    "    for opts in opts_sets:\n",
    "        high_rows = {}\n",
    "        for metatype in metatypes:\n",
    "            row = {}\n",
    "            df = get_table_from_group(varnodes_group_metatype(metatype), opts)\n",
    "            # get the \"ground truth\" varnodes for metatype\n",
    "            truth = df.iloc[:,0].sum()\n",
    "\n",
    "            # get the varnode compare score for metatype\n",
    "            level_sums = df.iloc[:,1:6].sum(axis=0)\n",
    "            weights = np.array(list(VarnodeCompareLevel.range()))\n",
    "            level_sums_weighted = np.multiply(weights, level_sums)\n",
    "            level_sums_weighted_sum = level_sums_weighted.sum()\n",
    "            score = level_sums_weighted_sum / (VarnodeCompareLevel.MATCH * truth)\n",
    "            row[\"Varnode comparison score [0,1]\"] = score\n",
    "\n",
    "            missed = df.iloc[:,1].sum()\n",
    "            matched = df.iloc[:,5].sum()\n",
    "            row[\"Varnodes fraction partially recovered\"] = (truth - missed) / truth\n",
    "            row[\"Varnodes fraction exactly recovered\"] = matched / truth\n",
    "            high_rows[MetaType.repr(metatype)] = row\n",
    "\n",
    "        high_df = pd.DataFrame.from_dict(high_rows, orient='index')\n",
    "        high_tablename = tablename\n",
    "        high_savepath = get_table_save_path(high_tablename, opts)\n",
    "        high_df.to_csv(high_savepath)\n",
    "\n",
    "        decomposed_rows = {}\n",
    "        for metatype in primitive_metatypes:\n",
    "            row = {}\n",
    "            df = get_table_from_group(decomposed_varnodes_group_metatype(metatype), opts)\n",
    "            # get the \"ground truth\" varnodes for metatype\n",
    "            truth = df.iloc[:,0].sum()\n",
    "\n",
    "            # get the varnode compare score for metatype\n",
    "            level_sums = df.iloc[:,1:6].sum(axis=0)\n",
    "            weights = np.array(list(VarnodeCompareLevel.range()))\n",
    "            level_sums_weighted = np.multiply(weights, level_sums)\n",
    "            level_sums_weighted_sum = level_sums_weighted.sum()\n",
    "            score = level_sums_weighted_sum / (VarnodeCompareLevel.MATCH * truth)\n",
    "            row[\"Varnode comparison score [0,1]\"] = score\n",
    "\n",
    "            missed = df.iloc[:,1].sum()\n",
    "            matched = df.iloc[:,5].sum()\n",
    "            row[\"Varnodes fraction partially recovered\"] = (truth - missed) / truth\n",
    "            row[\"Varnodes fraction exactly recovered\"] = matched / truth\n",
    "            decomposed_rows[MetaType.repr(metatype)] = row\n",
    "\n",
    "        decomposed_df = pd.DataFrame.from_dict(decomposed_rows, orient='index')\n",
    "        decomposed_tablename = tablename + \"-decomposed\"\n",
    "        decomposed_savepath = get_table_save_path(decomposed_tablename, opts)\n",
    "        decomposed_df.to_csv(decomposed_savepath)\n",
    "\n",
    "def get_metatype_recovery_summary_table(\n",
    "    opts: BuildOptions,\n",
    "    primitive: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    tname = \"metatype-recovery-summary\"\n",
    "    if primitive:\n",
    "        tname += \"-decomposed\"\n",
    "    return load_table_opts(tname, opts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_generate_metatype_recovery_with_levels_summaries = False\n",
    "\n",
    "tablename = \"metatype-recovery-summary-with-levels\"\n",
    "\n",
    "if not skip_generate_metatype_recovery_with_levels_summaries:\n",
    "    for opts in opts_sets:\n",
    "        for primitive in (True, False):\n",
    "            dfs = [\n",
    "                get_metatype_match_levels_table(opts, primitive=primitive),\n",
    "                get_metatype_recovery_summary_table(opts, primitive=primitive)\n",
    "            ]\n",
    "            df = pd.concat(\n",
    "                dfs,\n",
    "                axis=1\n",
    "            )\n",
    "            tname = tablename\n",
    "            caption = \"Summary of varnode recovery for each metatype\"\n",
    "            if primitive:\n",
    "                tname += \"-decomposed\"\n",
    "                caption = \"Summary of decomposed varnode recovery for each primitive metatype\"\n",
    "            savepath = get_table_save_path(tname, opts)\n",
    "            df.to_csv(savepath)\n",
    "                \n",
    "\n",
    "def get_metatype_recovery_summary_with_levels_table(\n",
    "    opts: BuildOptions,\n",
    "    primitive: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    tname = \"metatype-recovery-summary-with-levels\"\n",
    "    if primitive:\n",
    "        tname += \"-decomposed\"\n",
    "    return load_table_opts(tname, opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_generate_opts_varnodes_summary = False\n",
    "\n",
    "tablename = \"opts-varnodes-summary\"\n",
    "\n",
    "if not skip_generate_opts_varnodes_summary:\n",
    "    for primitive in (True, False):\n",
    "        grp = decomposed_varnodes_group if primitive else varnodes_group\n",
    "        _suffix = \" (decomposed)\" if primitive else \"\"\n",
    "        seriess = []\n",
    "        for opts in opts_sets:\n",
    "            df = get_table_from_group(grp, opts)\n",
    "            truth = df.iloc[:,0].sum()\n",
    "            row = df.iloc[:,1:6].sum(axis=0)\n",
    "            level_sums = row\n",
    "            weights = np.array(list(VarnodeCompareLevel.range()))\n",
    "            level_sums_weighted = np.multiply(weights, level_sums)\n",
    "            level_sums_weighted_sum = level_sums_weighted.sum()\n",
    "            score = level_sums_weighted_sum / (VarnodeCompareLevel.MATCH * truth)\n",
    "            row[\"Varnode comparison score [0,1]\" + _suffix] = score\n",
    "            missed = df.iloc[:,1].sum()\n",
    "            matched = df.iloc[:,5].sum()\n",
    "            row[\"Varnodes fraction partially recovered\" + _suffix] = (truth - missed) / truth\n",
    "            row[\"Varnodes fraction exactly recovered\" + _suffix] = matched / truth\n",
    "            seriess.append(row)\n",
    "        \n",
    "        tname = tablename\n",
    "        caption = \"Summary of high-level varnode recovery by compilation case\"\n",
    "        if primitive:\n",
    "            tablename += \"-decomposed\"\n",
    "            caption = \"Summary of decomposed varnode recovery by compilation case\"\n",
    "        \n",
    "        savepath = get_table_save_path_generic(tname)\n",
    "        \n",
    "        df = pd.DataFrame(\n",
    "            seriess,\n",
    "            index=opts_sets_keys\n",
    "        )\n",
    "        for colname in df.columns[0:5]:\n",
    "            df[colname] = df[colname].astype(int)\n",
    "        df.to_csv(savepath)\n",
    "\n",
    "def get_opts_varnodes_summary_table(primitive: bool = False) -> pd.DataFrame:\n",
    "    tname = \"opts-varnodes-summary\"\n",
    "    if primitive:\n",
    "        tname += \"-decomposed\"\n",
    "    df = load_table(tname)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_generate_opts_varnodes_summary_metatypes = False\n",
    "\n",
    "tablename = \"opts-varnodes-summary-metatypes\"\n",
    "\n",
    "if not skip_generate_opts_varnodes_summary_metatypes:\n",
    "    for primitive in (True, False):\n",
    "        dfs = [ get_metatype_recovery_summary_with_levels_table(opts, primitive=primitive) for opts in opts_sets ]\n",
    "        df = pd.concat(dfs, keys=opts_sets_keys, axis=0)\n",
    "        tname = tablename\n",
    "        caption = \"Summary of high-level varnode recovery by compilation case and metatype\"\n",
    "        if primitive:\n",
    "            tname += \"-decomposed\"\n",
    "            caption = \"Summary of decomposed varnode recovery by compilation case and primitive metatype\"\n",
    "        savepath = get_table_save_path_generic(tname)\n",
    "        df.to_csv(savepath)\n",
    "\n",
    "def get_opts_varnodes_summary_metatypes_table(primitive: bool = False) -> pd.DataFrame:\n",
    "    tname = \"opts-varnodes-summary-metatypes\"\n",
    "    if primitive:\n",
    "        tname += \"-decomposed\"\n",
    "    savepath = get_table_save_path_generic(tname)\n",
    "    return pd.read_csv(savepath, index_col=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_generate_opts_functions_summary = False\n",
    "\n",
    "tablename = \"opts-functions-summary\"\n",
    "\n",
    "if not skip_generate_opts_varnodes_summary:\n",
    "    rows = []\n",
    "    for opts in opts_sets:\n",
    "        df = get_table_from_group(functions_group, opts)\n",
    "        row = df.iloc[:,0:3].sum(axis=0)\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows, index=opts_sets_keys)\n",
    "    df[\"Functions recovery fraction\"] = df[\"Functions found\"] / df[\"Ground truth functions\"]\n",
    "\n",
    "    savepath = get_table_save_path_generic(tablename)\n",
    "    df.to_csv(savepath)\n",
    "\n",
    "def get_opts_functions_summary_table() -> pd.DataFrame:\n",
    "    return load_table(\"opts-functions-summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_generate_opts_bytes_summary = False\n",
    "\n",
    "tablename = \"opts-bytes-summary\"\n",
    "\n",
    "if not skip_generate_opts_bytes_summary:\n",
    "    rows = []\n",
    "    for opts in opts_sets:\n",
    "        df = get_table_from_group(bytes_group, opts)\n",
    "        row = df.iloc[:,0:3].sum(axis=0)\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows, index=opts_sets_keys)\n",
    "    df[\"Bytes recovery fraction\"] = df[\"Bytes found\"] / df[\"Ground truth data bytes\"]\n",
    "\n",
    "    savepath = get_table_save_path_generic(tablename)\n",
    "    df.to_csv(savepath)\n",
    "\n",
    "def get_opts_bytes_summary_table() -> pd.DataFrame:\n",
    "    return load_table(\"opts-bytes-summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_generate_opts_array_comparisons_summary = False\n",
    "\n",
    "tablename = \"opts-array-comparisons-summary\"\n",
    "\n",
    "if not skip_generate_opts_array_comparisons_summary:\n",
    "    rows = []\n",
    "    for opts in opts_sets:\n",
    "        df = get_table_from_group(array_comparisons_group, opts)\n",
    "        comparisons_col = df[\"Array comparisons\"]\n",
    "        total_comparisons = comparisons_col.sum()\n",
    "        series0 = df.iloc[:,0:3].sum(axis=0)\n",
    "        series1 = df.iloc[:,3:].transform(lambda col: col * comparisons_col, axis=0).sum(axis=0) / total_comparisons\n",
    "        row = pd.concat((series0, series1), axis=0)\n",
    "        rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        rows,\n",
    "        index=opts_sets_keys\n",
    "    )\n",
    "    df[\"Array varnodes inferred as array fraction\"] = df[\"Array varnodes inferred as array\"] / df[\"Ground truth array varnodes\"]\n",
    "    for colname in df.columns[0:3]:\n",
    "        df[colname] = df[colname].astype(int)\n",
    "    \n",
    "    savepath = get_table_save_path_generic(tablename)\n",
    "    df.to_csv(savepath)\n",
    "\n",
    "def get_opts_array_comparisons_summary_table() -> pd.DataFrame:\n",
    "    return load_table(\"opts-array-comparisons-summary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_generate_opts_overall_summary = False\n",
    "\n",
    "tablename = \"opts-overall-summary\"\n",
    "\n",
    "if not skip_generate_opts_overall_summary:\n",
    "    df_functions = get_opts_functions_summary_table()\n",
    "    df_varnodes = get_opts_varnodes_summary_table(primitive=False)\n",
    "    df_primitive_varnodes = get_opts_varnodes_summary_table(primitive=True)\n",
    "    df_bytes = get_opts_bytes_summary_table()\n",
    "\n",
    "    functions_recovery_fraction = df_functions[\"Functions recovery fraction\"]\n",
    "    varnodes = df_varnodes.iloc[:,5:]\n",
    "    varnodes_decomposed = df_primitive_varnodes.iloc[:,5:]\n",
    "    bytes_recovery_fraction = df_bytes[\"Bytes recovery fraction\"]\n",
    "\n",
    "    df = pd.concat(\n",
    "        (functions_recovery_fraction, varnodes, varnodes_decomposed, bytes_recovery_fraction),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    savepath = get_table_save_path_generic(tablename)\n",
    "    df.to_csv(savepath)\n",
    "\n",
    "def get_opts_overall_summary_table() -> pd.DataFrame:\n",
    "    return load_table(\"opts-overall-summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_opts_varnodes_summary_metatypes_table()\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/99536995.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n"
     ]
    }
   ],
   "source": [
    "skip_fix_metrics_groups_latex = False\n",
    "\n",
    "if not skip_fix_metrics_groups_latex:\n",
    "    for opts in opts_sets:\n",
    "        for grp in metrics_groups:\n",
    "            # load CSV file\n",
    "            df = get_table_from_group(grp, opts)\n",
    "\n",
    "            # save to LATEX file\n",
    "            latex_path = get_latex_path(grp.get_name(), opts)\n",
    "            df.to_latex(\n",
    "                latex_path,\n",
    "                header=['\\\\rotatebox{45}{' + \"\\_\".join(c.split(\"_\")) + '}' for c in df.columns],\n",
    "                escape=False,\n",
    "                longtable=True,\n",
    "                label=make_latex_label(grp.get_name() + suffix(opts)),\n",
    "                caption=\"{} {}\".format(grp.get_display_name(), opts_to_caption_suffix(opts)),\n",
    "                column_format=latex_column_format_str(df.shape[1] + 1),\n",
    "                float_format=\"{:.3f}\".format,\n",
    "                na_rep=\"-\"\n",
    "            )\n",
    "\n",
    "            # open the given file\n",
    "            with latex_path.open(\"r\") as f:\n",
    "                contents: str = f.read()\n",
    "\n",
    "            # find the '[' program name and replace with '{[}'\n",
    "            contents = contents.replace(\"[ \", \"{[} \")\n",
    "            with latex_path.open(\"w\") as f:\n",
    "                f.write(contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SummaryLatexTable = namedtuple(\"SummaryTableLatex\", [\n",
    "    \"tablename\",\n",
    "    \"caption\",\n",
    "    \"multirow\",\n",
    "    \"float_format\"\n",
    "], defaults=(\"\", \"\", False, \"{:.3f}\".format))\n",
    "\n",
    "summary_latex_tables = [\n",
    "\n",
    "    SummaryLatexTable(\n",
    "        tablename=\"opts-varnodes-summary\",\n",
    "        caption=\"Summary of high-level varnode recovery by compilation case\"\n",
    "    ),\n",
    "\n",
    "    SummaryLatexTable(\n",
    "        tablename=\"opts-varnodes-summary-decomposed\",\n",
    "        caption=\"Summary of decomposed varnode recovery by compilation case\"\n",
    "    ),\n",
    "\n",
    "    SummaryLatexTable(\n",
    "        tablename=\"opts-varnodes-summary-metatypes\",\n",
    "        caption=\"Summary of high-level varnode recovery by compilation case and metatype\",\n",
    "        multirow=True\n",
    "    ),\n",
    "\n",
    "    SummaryLatexTable(\n",
    "        tablename=\"opts-varnodes-summary-metatypes-decomposed\",\n",
    "        caption=\"Summary of decomposed varnode recovery by compilation case and primitive metatype\",\n",
    "        multirow=True\n",
    "    ),\n",
    "\n",
    "    SummaryLatexTable(\n",
    "        tablename=\"opts-functions-summary\",\n",
    "        caption=\"Summary of function recovery by compilation case\",\n",
    "        float_format=\"{:.4f}\".format\n",
    "    ),\n",
    "\n",
    "    SummaryLatexTable(\n",
    "        tablename=\"opts-bytes-summary\",\n",
    "        caption=\"Summary of data bytes recovery by compilation case\"\n",
    "    ),\n",
    "\n",
    "    SummaryLatexTable(\n",
    "        tablename=\"opts-array-comparisons-summary\",\n",
    "        caption=\"Summary of array recovery by compilation case\"\n",
    "    ),\n",
    "\n",
    "    SummaryLatexTable(\n",
    "        tablename=\"opts-overall-summary\",\n",
    "        caption=\"Aggregated recovery summary of functions, varnodes, and data bytes by compilation case\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5195/2725480240.py:7: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/2725480240.py:7: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/2725480240.py:7: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/2725480240.py:7: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/2725480240.py:7: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/2725480240.py:7: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/2725480240.py:7: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n",
      "/tmp/ipykernel_5195/2725480240.py:7: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex(\n"
     ]
    }
   ],
   "source": [
    "for tbl in summary_latex_tables:\n",
    "    df = load_table(tbl.tablename, multiindex=tbl.multirow)\n",
    "    savepath = get_latex_path_generic(tbl.tablename)\n",
    "    ncols = df.shape[1] + (1 if not tbl.multirow else 2)\n",
    "\n",
    "    # save to .tex file\n",
    "    df.to_latex(\n",
    "        savepath,\n",
    "        header=['\\\\rotatebox{45}{' + \"\\_\".join(c.split(\"_\")) + '}' for c in df.columns],\n",
    "        escape=False,\n",
    "        label=make_latex_label(tbl.tablename),\n",
    "        caption=tbl.caption,\n",
    "        column_format=latex_column_format_str(ncols),\n",
    "        multirow=tbl.multirow,\n",
    "        position=\"t\",\n",
    "        float_format=tbl.float_format,\n",
    "        na_rep=\"-\"\n",
    "    )\n",
    "\n",
    "    # if we want table to span full page, change \"table\" environment to \"table*\"\n",
    "    # open the given file\n",
    "    with savepath.open(\"r\") as f:\n",
    "        contents: str = f.read()\n",
    "\n",
    "    # change table to table*\n",
    "    contents = contents.replace(\"table\", \"table*\")\n",
    "    with savepath.open(\"w\") as f:\n",
    "        f.write(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "display(get_opts_functions_summary_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varnodes\n",
    "\n",
    "display(get_opts_varnodes_summary_table())\n",
    "display(get_opts_varnodes_summary_metatypes_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposed Varnodes\n",
    "\n",
    "display(get_opts_varnodes_summary_table(primitive=True))\n",
    "display(get_opts_varnodes_summary_metatypes_table(primitive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Bytes\n",
    "\n",
    "display(get_opts_bytes_summary_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "\n",
    "display(get_opts_overall_summary_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array Comparisons\n",
    "\n",
    "display(get_opts_array_comparisons_summary_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog = CoreutilsProgram(\"ls\")\n",
    "\n",
    "cmp = load_cmp(prog, debug_opts)\n",
    "\n",
    "records = []\n",
    "for record in select_comparable_varnode_compare_records(cmp):\n",
    "    if record.bytes_overlapped() < record.get_datatype().get_size():\n",
    "    # if record.get_compare_level() != VarnodeCompareLevel.MATCH:\n",
    "        records.append(record)\n",
    "        print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in records:\n",
    "    print(record.get_varnode())\n",
    "    print(record.get_varnode().get_var().get_parent_function().get_name())\n",
    "    print(record.get_var())\n",
    "    for cmp2 in record.get_comparisons():\n",
    "        print(\"\\t{}\".format(cmp2.get_right()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_cmp = cmp.flip()\n",
    "\n",
    "def filter_cmp_record(record: VarnodeCompareRecord) -> bool:\n",
    "    varnode = record.get_varnode()\n",
    "    var = varnode.get_var()\n",
    "    fn = var.get_parent_function()\n",
    "    return var.get_name() == \"hbuf\"\n",
    "\n",
    "flipped_records = list(filter(filter_cmp_record, select_comparable_varnode_compare_records(flipped_cmp)))\n",
    "\n",
    "for record in flipped_records:\n",
    "    print(record.get_varnode())\n",
    "    print(record.get_varnode().get_var().get_parent_function().get_name())\n",
    "    print(record.get_var())\n",
    "    for cmp2 in record.get_comparisons():\n",
    "        print(\"\\t{}\".format(cmp2.get_right()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebf8bf05a68ebde7d71715735c34f46ac9aa39a0c4d11ea58f3fb78ab998520e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
